{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcd8f46c-9f91-48ec-bad9-b6ca5507070c",
   "metadata": {},
   "source": [
    "# Part A: Logistic Regression (Bank Dataset) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222cb322-da07-4a06-b2ad-2e639fa3119f",
   "metadata": {},
   "source": [
    "## 1. Create a Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0ebfa79-f4ac-47a6-8f12-b9aa7d9247db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install ucimlrepo\n",
    "#already installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f97a05c-3dde-483e-b8db-07068b582a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>1506</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education default  balance housing loan  \\\n",
       "0   58    management  married   tertiary      no     2143     yes   no   \n",
       "1   44    technician   single  secondary      no       29     yes   no   \n",
       "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
       "3   47   blue-collar  married        NaN      no     1506     yes   no   \n",
       "4   33           NaN   single        NaN      no        1      no   no   \n",
       "\n",
       "  contact  day_of_week month  duration  campaign  pdays  previous poutcome   y  \n",
       "0     NaN            5   may       261         1     -1         0      NaN  no  \n",
       "1     NaN            5   may       151         1     -1         0      NaN  no  \n",
       "2     NaN            5   may        76         1     -1         0      NaN  no  \n",
       "3     NaN            5   may        92         1     -1         0      NaN  no  \n",
       "4     NaN            5   may       198         1     -1         0      NaN  no  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# Load the Bank Marketing dataset (UCI ID: 222)\n",
    "bank_data = fetch_ucirepo(id=222)\n",
    "\n",
    "# Extract features and target\n",
    "X = bank_data.data.features\n",
    "y = bank_data.data.targets\n",
    "\n",
    "# Combine into a single DataFrame for easier handling\n",
    "df = pd.concat([X, y], axis=1)\n",
    "\n",
    "# Display the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da06ba5-d9ea-4ca8-bdad-c5ef1a94324c",
   "metadata": {},
   "source": [
    "##### We fetch the **Bank Marketing dataset** using `fetch_ucirepo(id=222)`.\r\n",
    "\r\n",
    "The dataset includes information on clients contacted during a marketing campaign.\r\n",
    "\r\n",
    "- Features are stored in `X` and the target (`y`) indicates whether the client subscribed to a term deposit.\r\n",
    "- We combine both into a single DataFrame for preprocessing.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f54009f-b45c-4f09-a3f0-36bdd851a8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 17 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   age          45211 non-null  int64 \n",
      " 1   job          44923 non-null  object\n",
      " 2   marital      45211 non-null  object\n",
      " 3   education    43354 non-null  object\n",
      " 4   default      45211 non-null  object\n",
      " 5   balance      45211 non-null  int64 \n",
      " 6   housing      45211 non-null  object\n",
      " 7   loan         45211 non-null  object\n",
      " 8   contact      32191 non-null  object\n",
      " 9   day_of_week  45211 non-null  int64 \n",
      " 10  month        45211 non-null  object\n",
      " 11  duration     45211 non-null  int64 \n",
      " 12  campaign     45211 non-null  int64 \n",
      " 13  pdays        45211 non-null  int64 \n",
      " 14  previous     45211 non-null  int64 \n",
      " 15  poutcome     8252 non-null   object\n",
      " 16  y            45211 non-null  object\n",
      "dtypes: int64(7), object(10)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43b4db77-c1e3-4fb7-80a0-693597235529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>40.936210</td>\n",
       "      <td>1362.272058</td>\n",
       "      <td>15.806419</td>\n",
       "      <td>258.163080</td>\n",
       "      <td>2.763841</td>\n",
       "      <td>40.197828</td>\n",
       "      <td>0.580323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.618762</td>\n",
       "      <td>3044.765829</td>\n",
       "      <td>8.322476</td>\n",
       "      <td>257.527812</td>\n",
       "      <td>3.098021</td>\n",
       "      <td>100.128746</td>\n",
       "      <td>2.303441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>-8019.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>448.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>1428.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>319.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>95.000000</td>\n",
       "      <td>102127.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>4918.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>871.000000</td>\n",
       "      <td>275.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        balance   day_of_week      duration      campaign  \\\n",
       "count  45211.000000   45211.000000  45211.000000  45211.000000  45211.000000   \n",
       "mean      40.936210    1362.272058     15.806419    258.163080      2.763841   \n",
       "std       10.618762    3044.765829      8.322476    257.527812      3.098021   \n",
       "min       18.000000   -8019.000000      1.000000      0.000000      1.000000   \n",
       "25%       33.000000      72.000000      8.000000    103.000000      1.000000   \n",
       "50%       39.000000     448.000000     16.000000    180.000000      2.000000   \n",
       "75%       48.000000    1428.000000     21.000000    319.000000      3.000000   \n",
       "max       95.000000  102127.000000     31.000000   4918.000000     63.000000   \n",
       "\n",
       "              pdays      previous  \n",
       "count  45211.000000  45211.000000  \n",
       "mean      40.197828      0.580323  \n",
       "std      100.128746      2.303441  \n",
       "min       -1.000000      0.000000  \n",
       "25%       -1.000000      0.000000  \n",
       "50%       -1.000000      0.000000  \n",
       "75%       -1.000000      0.000000  \n",
       "max      871.000000    275.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31e77776-9747-46dc-ac31-2ca7870a2878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                0\n",
       "job              288\n",
       "marital            0\n",
       "education       1857\n",
       "default            0\n",
       "balance            0\n",
       "housing            0\n",
       "loan               0\n",
       "contact        13020\n",
       "day_of_week        0\n",
       "month              0\n",
       "duration           0\n",
       "campaign           0\n",
       "pdays              0\n",
       "previous           0\n",
       "poutcome       36959\n",
       "y                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "527b229c-c9ee-46c8-baf6-94b81caf314b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['management', 'technician', 'entrepreneur', 'blue-collar', nan,\n",
       "       'retired', 'admin.', 'services', 'self-employed', 'unemployed',\n",
       "       'housemaid', 'student'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's just confirm the unique values in one example column\n",
    "df['job'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "582250b3-e58b-4089-832b-c890532722fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['job', 'education', 'contact', 'poutcome']] = df[['job', 'education', 'contact', 'poutcome']].fillna('unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75484f2-a219-4e4d-aac2-21640eeaebae",
   "metadata": {},
   "source": [
    "#### Handling Missing Values in the Bank Dataset\n",
    "\n",
    "Although the UCI repository documentation states that the \"bank-full.csv\" dataset has **no missing values**, when we load it using the `ucimlrepo` package, we observe `NaN` values in several categorical columns such as:\n",
    "\n",
    "- job\n",
    "- education\n",
    "- contact\n",
    "- poutcome\n",
    "\n",
    "These missing values are not due to missing data in the original dataset, but instead, are the result of the loader interpreting 'unknown' entries as `NaN` (which is common in some automated preprocessing pipelines).\n",
    "\n",
    "Rather than dropping these rows or applying imputation (which is not meaningful for categorical data), we restore them to their original intended value of 'unknown'. This allows us to retain all records and let the machine learning model learn from the \"unknown\" category as a distinct feature level.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "462e4296-e492-4879-86e3-3be03ff16dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode categorical variables\n",
    "df_encoded = pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ae569f-f0e1-4776-aa0c-79ed8eff3434",
   "metadata": {},
   "source": [
    "#### Encoding Categorical Variables\n",
    "\n",
    "To build a logistic regression model, all input features must be numeric.\n",
    "\n",
    "Since many features in this dataset (like `job`, `marital`, `education`, etc.) are categorical, we use **one-hot encoding** (`pd.get_dummies`) to convert them into binary columns.\n",
    "\n",
    "This creates new columns for each category and allows the model to interpret them properly.\n",
    "\n",
    "We drop the first category from each feature (`drop_first=True`) to avoid multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35feb4f8-8cab-480f-92a7-93b2d37062d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df_encoded.drop('y_yes', axis=1)\n",
    "y = df_encoded['y_yes']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cfd5c4-4e7f-4c2c-bf13-4e16b50795cb",
   "metadata": {},
   "source": [
    "#### Split Features and Target\n",
    "\n",
    "We separate the dataset into:\n",
    "- `X` = all feature columns (input)\n",
    "- `y` = target column: `'y'`, which contains 'yes' or 'no'\n",
    "\n",
    "We'll also convert `'yes'`/`'no'` to binary values (`1` for 'yes', `0` for 'no') so that logistic regression can model a binary outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3cfb11b-0178-4c33-a43f-e9e32e763de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598e3197-ece2-47b6-9fc9-2e5e5fdf8a99",
   "metadata": {},
   "source": [
    "#### Train-Test Split\n",
    "\n",
    "We divide the dataset into training and testing sets using an 80:20 split.  \n",
    "This helps us evaluate how well the model generalizes to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02898f86-3ce2-4439-afd3-04d2e6c17541",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training data, transform both train and test sets\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6799018c-2917-45bb-a877-63381af1cb73",
   "metadata": {},
   "source": [
    "### Feature Scaling with StandardScaler\n",
    "\n",
    "Since logistic regression uses gradient descent, having features with different ranges (e.g., age vs. balance) can slow convergence.\n",
    "\n",
    "We use `StandardScaler` to normalize the input features so that they have a mean of 0 and standard deviation of 1.\n",
    "\n",
    "This improves model performance and prevents convergence issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b660b74-df59-49fe-be61-5185615d60d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=42)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train the logistic regression model using scaled features\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dae3eb-bc6f-4a2c-9538-29423e406f3d",
   "metadata": {},
   "source": [
    "#### Training the Logistic Regression Model\n",
    "\n",
    "We train the logistic regression model using the **scaled training data**. Scaling is important because it helps the solver (`lbfgs`) converge faster, especially when feature values vary widely.\n",
    "\n",
    "**Parameters used:**\n",
    "- `max_iter=1000`: Increases max iterations to avoid convergence issues.\n",
    "- `random_state=42`: Ensures consistent results.\n",
    "\n",
    "The model will now learn to predict if a customer will subscribe to a term deposit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3981b22-238f-4cac-9365-ef9991a93ca6",
   "metadata": {},
   "source": [
    "## 2. Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a263551a-99e6-4bc0-b684-1766f5896415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Performance:\n",
      "Accuracy: 0.901249585314608\n",
      "Precision: 0.643979057591623\n",
      "Recall: 0.3487712665406427\n",
      "F1 Score: 0.45248313917841815\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      0.97      0.95      7985\n",
      "        True       0.64      0.35      0.45      1058\n",
      "\n",
      "    accuracy                           0.90      9043\n",
      "   macro avg       0.78      0.66      0.70      9043\n",
      "weighted avg       0.89      0.90      0.89      9043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = lr_model.predict(X_test_scaled)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Logistic Regression Performance:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cede86-2576-4ce4-8352-460bdff820dd",
   "metadata": {},
   "source": [
    "#### Model Evaluation\n",
    "\n",
    "We evaluated the performance of our logistic regression model using four key metrics:\n",
    "\n",
    "- **Accuracy**: How often the model gets predictions right.\n",
    "- **Precision**: Of all positive predictions, how many were correct.\n",
    "- **Recall**: Of all actual positives, how many did we catch.\n",
    "- **F1 Score**: Harmonic mean of precision and recall.\n",
    "\n",
    "We use `classification_report` for a quick summary. The metrics help us understand if the model performs well across both classes — especially the minority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b80e63-f917-4550-aa82-90bbf8e58c19",
   "metadata": {},
   "source": [
    "## 3. Create two Regularized Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c6e882-820f-4944-969f-728a57bff5ea",
   "metadata": {},
   "source": [
    "#### L1 (Lasso) regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6355d4af-54a2-43dc-b134-d67c3a5e8c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 Regularized Logistic Regression Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      0.97      0.95      7985\n",
      "        True       0.65      0.35      0.45      1058\n",
      "\n",
      "    accuracy                           0.90      9043\n",
      "   macro avg       0.78      0.66      0.70      9043\n",
      "weighted avg       0.89      0.90      0.89      9043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# L1 Regularized Logistic Regression (Lasso)\n",
    "lr_l1 = LogisticRegression(penalty='l1', solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "lr_l1.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_l1 = lr_l1.predict(X_test_scaled)\n",
    "\n",
    "# Print classification report\n",
    "print(\"L1 Regularized Logistic Regression Results:\\n\")\n",
    "print(classification_report(y_test, y_pred_l1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfdd6ec-57c5-4cc2-88e3-6e68787ffb0d",
   "metadata": {},
   "source": [
    "#### L1 Regularized Logistic Regression (Lasso)\n",
    "\n",
    "- **L1 regularization** adds a penalty equal to the absolute values of the model coefficients.\n",
    "- This encourages sparsity — some feature weights can become zero, acting like built-in feature selection.\n",
    "- We used the `'liblinear'` solver, which supports L1 penalty.\n",
    "- The model is trained and tested using the scaled dataset, and performance is reported using standard classification metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01db49f-a4ef-4631-bdab-f22cfa779d71",
   "metadata": {},
   "source": [
    "#### L2 (Ridge) regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3890896a-334b-440d-8294-776aab788db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 Regularized Logistic Regression Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      0.97      0.95      7985\n",
      "        True       0.64      0.35      0.45      1058\n",
      "\n",
      "    accuracy                           0.90      9043\n",
      "   macro avg       0.78      0.66      0.70      9043\n",
      "weighted avg       0.89      0.90      0.89      9043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# L2 Regularized Logistic Regression (Ridge)\n",
    "lr_l2 = LogisticRegression(penalty='l2', C=1.0, max_iter=1000, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "lr_l2.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_l2 = lr_l2.predict(X_test_scaled)\n",
    "\n",
    "# Print classification report\n",
    "print(\"L2 Regularized Logistic Regression Results:\\n\")\n",
    "print(classification_report(y_test, y_pred_l2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7dc836-a435-4f54-98c2-7301690d1b24",
   "metadata": {},
   "source": [
    "#### L2 Regularized Logistic Regression (Ridge)\n",
    "\n",
    "- **L2 regularization** adds a penalty equal to the square of the magnitude of coefficients.\n",
    "- It shrinks all coefficients but does not eliminate any features completely.\n",
    "- This helps prevent overfitting, especially in models with many correlated features.\n",
    "- The model is trained and evaluated just like the L1 model for fair comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3c1256-b22b-4419-bbad-02ea51387445",
   "metadata": {},
   "source": [
    "## 4. Use KNN as a baseline model and compare its performance with Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e211cc9-e290-42cd-9eff-09320bb8fd00",
   "metadata": {},
   "source": [
    "#### Find the Optimal k using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71302252-7ec8-4298-9280-8be843ef8cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value of k: 11\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {'n_neighbors': list(range(1, 21))}\n",
    "\n",
    "# GridSearchCV to find best k\n",
    "grid_search_knn = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search_knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best k\n",
    "best_k = grid_search_knn.best_params_['n_neighbors']\n",
    "print(\"Best value of k:\", best_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2ff805-18af-4ba5-a7cb-9dff579b2fdc",
   "metadata": {},
   "source": [
    "*We use GridSearchCV to find the best value of k (number of neighbors) for the KNN model.*\n",
    "\n",
    "*A range of values from 1 to 20 is tested with 5-fold cross-validation.*\n",
    "\n",
    "*The model with the highest cross-validated accuracy is selected.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac779cc-13f6-4219-b336-a41cde4375f2",
   "metadata": {},
   "source": [
    "#### Train and Evaluate KNN with Best k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4649446a-3555-4673-ba46-29349b863671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.91      0.98      0.94      7985\n",
      "        True       0.63      0.26      0.37      1058\n",
      "\n",
      "    accuracy                           0.90      9043\n",
      "   macro avg       0.77      0.62      0.66      9043\n",
      "weighted avg       0.88      0.90      0.88      9043\n",
      "\n",
      "Training + Prediction Time (KNN): 0.7718 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=best_k)\n",
    "\n",
    "start_time = time.time()\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "y_pred_knn = knn.predict(X_test_scaled)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"KNN Classification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "print(\"Training + Prediction Time (KNN):\", round(end_time - start_time, 4), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d3ba76-4b7e-43b3-bc7d-126ee57d032e",
   "metadata": {},
   "source": [
    "*We train a KNN classifier using the best k obtained from GridSearchCV.*\n",
    "\n",
    "*Training time is recorded using the time module.*\n",
    "\n",
    "*Performance is evaluated using accuracy, precision, recall, and F1-score.*\n",
    "\n",
    "*KNN has no trainable parameters and is computationally expensive during prediction.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4d32f0-ca43-4349-a5f7-68543ced08b4",
   "metadata": {},
   "source": [
    "#### Train and Evaluate Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c5c7dd2e-4837-4b7d-a4f6-7d0c88a656fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      0.97      0.95      7985\n",
      "        True       0.64      0.35      0.45      1058\n",
      "\n",
      "    accuracy                           0.90      9043\n",
      "   macro avg       0.78      0.66      0.70      9043\n",
      "weighted avg       0.89      0.90      0.89      9043\n",
      "\n",
      "Training + Prediction Time (LogReg): 0.0404 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "start_time = time.time()\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "y_pred_lr = lr.predict(X_test_scaled)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Logistic Regression Classification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "print(\"Training + Prediction Time (LogReg):\", round(end_time - start_time, 4), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5227e4fe-61ab-4c5e-a0f4-fd3dd04e75fb",
   "metadata": {},
   "source": [
    "*We train a logistic regression model using scaled training data.*\n",
    "\n",
    "*Training + prediction time is measured.*\n",
    "\n",
    "*Performance metrics are obtained using classification_report.*\n",
    "\n",
    "*Logistic regression is a parametric model and learns coefficients for each feature.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46eca7e-872f-4051-b607-9816b7586905",
   "metadata": {},
   "source": [
    "#### Why KNN is Worse than Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef52ce9-5a4c-4e2f-963f-44959d7222b9",
   "metadata": {},
   "source": [
    "**In this task, KNN performs worse than Logistic Regression, and here's why:**\n",
    "\n",
    "**1. Model Performance on Imbalanced Data**\n",
    "\n",
    "The dataset presents an imbalance, with the True class (indicating a positive outcome) being significantly less prevalent.\n",
    "\n",
    "Logistic Regression demonstrates superior performance on the minority class:\n",
    "\n",
    "It attains higher recall and F1-score for the True class in comparison to KNN.\n",
    "\n",
    "KNN is particularly sensitive to class imbalance, often resulting in a bias towards the majority class (False), which adversely affects the detection of the minority class.\n",
    "\n",
    "**2. Number of Trainable Parameters**\n",
    "\n",
    "Logistic Regression operates by learning a fixed set of weights (trainable parameters), which enhances its efficiency during the prediction phase.\n",
    "\n",
    "Conversely, KNN does not engage in parameter training; instead, it retains the entire training dataset and conducts computations at the time of prediction, rendering it computationally intensive.\n",
    "\n",
    "**3. Training and Prediction Time**\n",
    "\n",
    "Logistic Regression is markedly quicker in making predictions due to its reliance on learned weights.\n",
    "\n",
    "In contrast, KNN is slower, as it necessitates the calculation of distances between the test instance and all training samples each time a prediction is made.\n",
    "\n",
    "**4. Scalability and Generalization**\n",
    "\n",
    "Logistic Regression exhibits superior generalization to unseen data by establishing a global decision boundary.\n",
    "\n",
    "KNN, however, is prone to overfitting, particularly in high-dimensional spaces, and is vulnerable to noise and irrelevant features.\n",
    "\n",
    "**5. Explainability**\n",
    "\n",
    "Logistic Regression provides interpretability through its coefficients.\n",
    "\n",
    "KNN, on the other hand, lacks a straightforward interpretation regarding how input features affect the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7180a9c4-7fab-46a8-a641-c3a20c308f9f",
   "metadata": {},
   "source": [
    "# Part B: SVM Classification (Grid Stability Dataset) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03b16fb-2c43-46b0-98b2-4b14db5cd085",
   "metadata": {},
   "source": [
    "## 5. Load the Electrical Grid Stability Dataset and Print Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "55a5d037-359c-4f88-920f-8027464ec4e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stab</th>\n",
       "      <th>stabf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.959060</td>\n",
       "      <td>3.079885</td>\n",
       "      <td>8.381025</td>\n",
       "      <td>9.780754</td>\n",
       "      <td>3.763085</td>\n",
       "      <td>-0.782604</td>\n",
       "      <td>-1.257395</td>\n",
       "      <td>-1.723086</td>\n",
       "      <td>0.650456</td>\n",
       "      <td>0.859578</td>\n",
       "      <td>0.887445</td>\n",
       "      <td>0.958034</td>\n",
       "      <td>0.055347</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.304097</td>\n",
       "      <td>4.902524</td>\n",
       "      <td>3.047541</td>\n",
       "      <td>1.369357</td>\n",
       "      <td>5.067812</td>\n",
       "      <td>-1.940058</td>\n",
       "      <td>-1.872742</td>\n",
       "      <td>-1.255012</td>\n",
       "      <td>0.413441</td>\n",
       "      <td>0.862414</td>\n",
       "      <td>0.562139</td>\n",
       "      <td>0.781760</td>\n",
       "      <td>-0.005957</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.971707</td>\n",
       "      <td>8.848428</td>\n",
       "      <td>3.046479</td>\n",
       "      <td>1.214518</td>\n",
       "      <td>3.405158</td>\n",
       "      <td>-1.207456</td>\n",
       "      <td>-1.277210</td>\n",
       "      <td>-0.920492</td>\n",
       "      <td>0.163041</td>\n",
       "      <td>0.766689</td>\n",
       "      <td>0.839444</td>\n",
       "      <td>0.109853</td>\n",
       "      <td>0.003471</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.716415</td>\n",
       "      <td>7.669600</td>\n",
       "      <td>4.486641</td>\n",
       "      <td>2.340563</td>\n",
       "      <td>3.963791</td>\n",
       "      <td>-1.027473</td>\n",
       "      <td>-1.938944</td>\n",
       "      <td>-0.997374</td>\n",
       "      <td>0.446209</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.929381</td>\n",
       "      <td>0.362718</td>\n",
       "      <td>0.028871</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.134112</td>\n",
       "      <td>7.608772</td>\n",
       "      <td>4.943759</td>\n",
       "      <td>9.857573</td>\n",
       "      <td>3.525811</td>\n",
       "      <td>-1.125531</td>\n",
       "      <td>-1.845975</td>\n",
       "      <td>-0.554305</td>\n",
       "      <td>0.797110</td>\n",
       "      <td>0.455450</td>\n",
       "      <td>0.656947</td>\n",
       "      <td>0.820923</td>\n",
       "      <td>0.049860</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       "0  2.959060  3.079885  8.381025  9.780754  3.763085 -0.782604 -1.257395   \n",
       "1  9.304097  4.902524  3.047541  1.369357  5.067812 -1.940058 -1.872742   \n",
       "2  8.971707  8.848428  3.046479  1.214518  3.405158 -1.207456 -1.277210   \n",
       "3  0.716415  7.669600  4.486641  2.340563  3.963791 -1.027473 -1.938944   \n",
       "4  3.134112  7.608772  4.943759  9.857573  3.525811 -1.125531 -1.845975   \n",
       "\n",
       "         p4        g1        g2        g3        g4      stab     stabf  \n",
       "0 -1.723086  0.650456  0.859578  0.887445  0.958034  0.055347  unstable  \n",
       "1 -1.255012  0.413441  0.862414  0.562139  0.781760 -0.005957    stable  \n",
       "2 -0.920492  0.163041  0.766689  0.839444  0.109853  0.003471  unstable  \n",
       "3 -0.997374  0.446209  0.976744  0.929381  0.362718  0.028871  unstable  \n",
       "4 -0.554305  0.797110  0.455450  0.656947  0.820923  0.049860  unstable  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df2 = pd.read_csv('grid_stability.csv')  \n",
    "\n",
    "# Display first few rows (optional)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0ee55d38-2c0d-4892-9e76-fef0432193b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   tau1    10000 non-null  float64\n",
      " 1   tau2    10000 non-null  float64\n",
      " 2   tau3    10000 non-null  float64\n",
      " 3   tau4    10000 non-null  float64\n",
      " 4   p1      10000 non-null  float64\n",
      " 5   p2      10000 non-null  float64\n",
      " 6   p3      10000 non-null  float64\n",
      " 7   p4      10000 non-null  float64\n",
      " 8   g1      10000 non-null  float64\n",
      " 9   g2      10000 non-null  float64\n",
      " 10  g3      10000 non-null  float64\n",
      " 11  g4      10000 non-null  float64\n",
      " 12  stab    10000 non-null  float64\n",
      " 13  stabf   10000 non-null  object \n",
      "dtypes: float64(13), object(1)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "707ce363-6f56-4ee6-b0ac-7af0a97d8c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tau1     0\n",
       "tau2     0\n",
       "tau3     0\n",
       "tau4     0\n",
       "p1       0\n",
       "p2       0\n",
       "p3       0\n",
       "p4       0\n",
       "g1       0\n",
       "g2       0\n",
       "g3       0\n",
       "g4       0\n",
       "stab     0\n",
       "stabf    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for missing values\n",
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "245ee2f6-08f1-4287-857e-66cd26450972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.250000</td>\n",
       "      <td>5.250001</td>\n",
       "      <td>5.250004</td>\n",
       "      <td>5.249997</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.015731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.742548</td>\n",
       "      <td>2.742549</td>\n",
       "      <td>2.742549</td>\n",
       "      <td>2.742556</td>\n",
       "      <td>0.752160</td>\n",
       "      <td>0.433035</td>\n",
       "      <td>0.433035</td>\n",
       "      <td>0.433035</td>\n",
       "      <td>0.274256</td>\n",
       "      <td>0.274255</td>\n",
       "      <td>0.274255</td>\n",
       "      <td>0.274255</td>\n",
       "      <td>0.036919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.500793</td>\n",
       "      <td>0.500141</td>\n",
       "      <td>0.500788</td>\n",
       "      <td>0.500473</td>\n",
       "      <td>1.582590</td>\n",
       "      <td>-1.999891</td>\n",
       "      <td>-1.999945</td>\n",
       "      <td>-1.999926</td>\n",
       "      <td>0.050009</td>\n",
       "      <td>0.050053</td>\n",
       "      <td>0.050054</td>\n",
       "      <td>0.050028</td>\n",
       "      <td>-0.080760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.874892</td>\n",
       "      <td>2.875140</td>\n",
       "      <td>2.875522</td>\n",
       "      <td>2.874950</td>\n",
       "      <td>3.218300</td>\n",
       "      <td>-1.624901</td>\n",
       "      <td>-1.625025</td>\n",
       "      <td>-1.624960</td>\n",
       "      <td>0.287521</td>\n",
       "      <td>0.287552</td>\n",
       "      <td>0.287514</td>\n",
       "      <td>0.287494</td>\n",
       "      <td>-0.015557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.250004</td>\n",
       "      <td>5.249981</td>\n",
       "      <td>5.249979</td>\n",
       "      <td>5.249734</td>\n",
       "      <td>3.751025</td>\n",
       "      <td>-1.249966</td>\n",
       "      <td>-1.249974</td>\n",
       "      <td>-1.250007</td>\n",
       "      <td>0.525009</td>\n",
       "      <td>0.525003</td>\n",
       "      <td>0.525015</td>\n",
       "      <td>0.525002</td>\n",
       "      <td>0.017142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.624690</td>\n",
       "      <td>7.624893</td>\n",
       "      <td>7.624948</td>\n",
       "      <td>7.624838</td>\n",
       "      <td>4.282420</td>\n",
       "      <td>-0.874977</td>\n",
       "      <td>-0.875043</td>\n",
       "      <td>-0.875065</td>\n",
       "      <td>0.762435</td>\n",
       "      <td>0.762490</td>\n",
       "      <td>0.762440</td>\n",
       "      <td>0.762433</td>\n",
       "      <td>0.044878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.999469</td>\n",
       "      <td>9.999837</td>\n",
       "      <td>9.999450</td>\n",
       "      <td>9.999443</td>\n",
       "      <td>5.864418</td>\n",
       "      <td>-0.500108</td>\n",
       "      <td>-0.500072</td>\n",
       "      <td>-0.500025</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999930</td>\n",
       "      <td>0.109403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tau1          tau2          tau3          tau4            p1  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       5.250000      5.250001      5.250004      5.249997      3.750000   \n",
       "std        2.742548      2.742549      2.742549      2.742556      0.752160   \n",
       "min        0.500793      0.500141      0.500788      0.500473      1.582590   \n",
       "25%        2.874892      2.875140      2.875522      2.874950      3.218300   \n",
       "50%        5.250004      5.249981      5.249979      5.249734      3.751025   \n",
       "75%        7.624690      7.624893      7.624948      7.624838      4.282420   \n",
       "max        9.999469      9.999837      9.999450      9.999443      5.864418   \n",
       "\n",
       "                 p2            p3            p4            g1            g2  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean      -1.250000     -1.250000     -1.250000      0.525000      0.525000   \n",
       "std        0.433035      0.433035      0.433035      0.274256      0.274255   \n",
       "min       -1.999891     -1.999945     -1.999926      0.050009      0.050053   \n",
       "25%       -1.624901     -1.625025     -1.624960      0.287521      0.287552   \n",
       "50%       -1.249966     -1.249974     -1.250007      0.525009      0.525003   \n",
       "75%       -0.874977     -0.875043     -0.875065      0.762435      0.762490   \n",
       "max       -0.500108     -0.500072     -0.500025      0.999937      0.999944   \n",
       "\n",
       "                 g3            g4          stab  \n",
       "count  10000.000000  10000.000000  10000.000000  \n",
       "mean       0.525000      0.525000      0.015731  \n",
       "std        0.274255      0.274255      0.036919  \n",
       "min        0.050054      0.050028     -0.080760  \n",
       "25%        0.287514      0.287494     -0.015557  \n",
       "50%        0.525015      0.525002      0.017142  \n",
       "75%        0.762440      0.762433      0.044878  \n",
       "max        0.999982      0.999930      0.109403  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aca35f44-f110-4c3c-b22e-bc75250c90ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 14)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the shape of the dataset\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dc566b-cc0d-4599-bcd6-39696eb87f8b",
   "metadata": {},
   "source": [
    "*The dataset used is the Electrical Grid Stability Simulated Data.*\n",
    "\n",
    "*We load it using pandas.read_csv() and print the dimensions using .shape.*\n",
    "\n",
    "*This gives us the number of rows (samples) and columns (features + target).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7d4dc201-b0d8-4d0f-a9eb-d7ec7932bff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature and Target Split\n",
    "# 'stabf' is the target variable and the rest are features\n",
    "\n",
    "X = df2.drop('stabf', axis=1)\n",
    "y = df2['stabf']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad18225a-373b-44ff-a3bc-444753c009e6",
   "metadata": {},
   "source": [
    "We separate the dataset into:\n",
    "\n",
    "Features (X) – all columns except the target.\n",
    "\n",
    "Target (y) – the stabf column which we aim to predict.\n",
    "\n",
    "This separation is essential before performing modeling and preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9f5fcb3d-9721-4e72-8b30-3331ab11e51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the Target Labels\n",
    "# Convert categorical labels to numerical values\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)  # For example: 'stable' → 1, 'unstable' → 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8500e5e6-65c7-42c2-98c0-2841196d4631",
   "metadata": {},
   "source": [
    "The target column stabf contains categorical labels like \"stable\" and \"unstable\". Most machine learning models require numeric values, so we use LabelEncoder to convert these text labels into binary numeric values:\n",
    "\n",
    "\"unstable\" → 0\n",
    "\n",
    "\"stable\" → 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f9f70f51-641c-4113-83dc-86f760a26b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea0fdd2-0999-4336-9ffd-c3cf6b5ade64",
   "metadata": {},
   "source": [
    "*We split the data into a training set (80%) and a test set (20%) using train_test_split. This allows us to train the model on one portion of the data and evaluate its performance on unseen data.*\n",
    "\n",
    "*We set random_state=42 to ensure reproducibility.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "16ad008a-85a9-4ea1-8d97-76976463e4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7731127a-8201-45c6-ad0a-e8e8ce2b2f19",
   "metadata": {},
   "source": [
    "*SVM models are sensitive to the scale of features. To ensure fair treatment of all features, we apply standardization using StandardScaler, which transforms the data so that each feature has:*\n",
    "\n",
    "Mean = 0\n",
    "\n",
    "Standard Deviation = 1\n",
    "\n",
    "*We fit the scaler on the training set and transform both training and test sets to avoid data leakage.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20175c6b-e3fc-47d1-8b28-c4f1db8678f0",
   "metadata": {},
   "source": [
    "## 6. SVM Classification with 3 Different Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b08e0f-fa6b-499f-bcd7-0f8fcea24ab4",
   "metadata": {},
   "source": [
    "#### SVM with Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "aa8439de-277a-4fc1-bab3-f28528d83e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with Linear Kernel:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       693\n",
      "           1       1.00      1.00      1.00      1307\n",
      "\n",
      "    accuracy                           1.00      2000\n",
      "   macro avg       1.00      1.00      1.00      2000\n",
      "weighted avg       1.00      1.00      1.00      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# SVM with Linear Kernel\n",
    "svm_linear = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "svm_linear.fit(X_train_scaled, y_train)\n",
    "y_pred_linear = svm_linear.predict(X_test_scaled)\n",
    "\n",
    "print(\"SVM with Linear Kernel:\\n\")\n",
    "print(classification_report(y_test, y_pred_linear))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf6a965-cb00-4070-b650-454c3936ecb8",
   "metadata": {},
   "source": [
    "*We trained an SVM classifier with a linear kernel, which assumes that the classes are linearly separable. The model was trained on scaled features and evaluated using standard classification metrics.*\n",
    "\n",
    "**The model achieved perfect accuracy (100%) on the test data.**\n",
    "\n",
    "*Both classes (0 and 1) were predicted with precision, recall, and F1-score of 1.00.*\n",
    "\n",
    "*This suggests the data is highly linearly separable, and the linear kernel is a great fit.*\n",
    "\n",
    "*No misclassifications occurred.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856bd282-ea00-4a71-b6bd-961f5fa2913c",
   "metadata": {},
   "source": [
    "#### SVM with RBF Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "29a6afc6-7403-4a19-b40d-d349c7c9d96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with RBF Kernel:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       693\n",
      "           1       0.99      0.98      0.99      1307\n",
      "\n",
      "    accuracy                           0.98      2000\n",
      "   macro avg       0.98      0.98      0.98      2000\n",
      "weighted avg       0.98      0.98      0.98      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM with RBF Kernel\n",
    "svm_rbf = SVC(kernel='rbf', C=1.0, random_state=42)\n",
    "svm_rbf.fit(X_train_scaled, y_train)\n",
    "y_pred_rbf = svm_rbf.predict(X_test_scaled)\n",
    "\n",
    "print(\"SVM with RBF Kernel:\\n\")\n",
    "print(classification_report(y_test, y_pred_rbf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228a31a4-0975-4e4c-b25d-2ecb714422d9",
   "metadata": {},
   "source": [
    "*We used the RBF kernel, which is useful for non-linear classification problems. It maps the input space into higher dimensions to find a suitable decision boundary.*\n",
    "\n",
    "**The RBF model achieved 98% accuracy, which is excellent but slightly below the linear kernel.**\n",
    "\n",
    "*A few misclassifications are present, especially in class 0.*\n",
    "\n",
    "*RBF kernel might be slightly overfitting or unnecessary here, since linear separation already performs perfectly.*\n",
    "\n",
    "*Useful in more complex datasets, but not essential in this case.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3595c46c-c8d4-4aad-bedc-1f5ce9ae92f8",
   "metadata": {},
   "source": [
    "#### SVM with Polynomial Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "27609b77-a60c-46a5-88c3-3f03ca700c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with Polynomial Kernel:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       693\n",
      "           1       0.97      0.99      0.98      1307\n",
      "\n",
      "    accuracy                           0.97      2000\n",
      "   macro avg       0.97      0.97      0.97      2000\n",
      "weighted avg       0.97      0.97      0.97      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM with Polynomial Kernel\n",
    "svm_poly = SVC(kernel='poly', degree=3, C=1.0, random_state=42)\n",
    "svm_poly.fit(X_train_scaled, y_train)\n",
    "y_pred_poly = svm_poly.predict(X_test_scaled)\n",
    "\n",
    "print(\"SVM with Polynomial Kernel:\\n\")\n",
    "print(classification_report(y_test, y_pred_poly))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcfea6e-ee79-4306-9dc2-33b36f89bf22",
   "metadata": {},
   "source": [
    "*We applied a polynomial kernel of degree 3, which captures interactions between features up to a cubic level. It’s more complex and non-linear in nature.*\n",
    "\n",
    "**The polynomial kernel achieved 97% accuracy, which is still high, but slightly worse than both linear and RBF kernels.**\n",
    "\n",
    "*Some misclassification occurred, especially for class 0 (recall = 0.95).*\n",
    "\n",
    "*Indicates potential overfitting or unnecessary complexity for this dataset.*\n",
    "\n",
    "*Best suited when the data requires modeling polynomial feature interactions.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522097aa-7616-4a7a-b573-5e2a12dd5278",
   "metadata": {},
   "source": [
    "## 7. Hyperparameter Tuning: SVM “C” Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2c4816-222a-49e5-8ed4-fc19d93323ad",
   "metadata": {},
   "source": [
    "### Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dedd2f5e-9811-4ccd-ba1d-62870d36de45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4236704c-16c6-406e-9ac9-9b4f8aef6f82",
   "metadata": {},
   "source": [
    "**The C parameter in SVM controls the trade-off between a smooth decision boundary and classifying training points correctly:**\n",
    "\n",
    "*Low C: Makes the margin wider, allowing for more misclassification.*\n",
    "\n",
    "*High C: Tries to classify all training data points correctly, resulting in a narrow margin.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b034358d-95b5-41cb-82ff-6f7a3779ed22",
   "metadata": {},
   "source": [
    "*GridSearchCV is used to search over different C values.*\n",
    "\n",
    "*Each model is trained on the scaled training data.*\n",
    "\n",
    "*The best model (best_estimator_) is selected based on accuracy.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d4cee49c-d117-4448-a357-2272ace36fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C (Linear): {'C': 100}\n",
      "Accuracy (Linear): 0.998\n",
      "Classification Report (Linear):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       693\n",
      "           1       1.00      1.00      1.00      1307\n",
      "\n",
      "    accuracy                           1.00      2000\n",
      "   macro avg       1.00      1.00      1.00      2000\n",
      "weighted avg       1.00      1.00      1.00      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Linear Kernel \n",
    "grid_linear = GridSearchCV(SVC(kernel='linear', random_state=42), param_grid, scoring='accuracy')\n",
    "grid_linear.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_linear = grid_linear.best_estimator_\n",
    "y_pred_linear = best_linear.predict(X_test_scaled)\n",
    "\n",
    "print(\"Best C (Linear):\", grid_linear.best_params_)\n",
    "print(\"Accuracy (Linear):\", accuracy_score(y_test, y_pred_linear))\n",
    "print(\"Classification Report (Linear):\\n\", classification_report(y_test, y_pred_linear))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e9be3b-5731-4a63-a741-8ae514adf49b",
   "metadata": {},
   "source": [
    "**Report:**\n",
    "\n",
    "*Precision, Recall, F1-score: All values ~1.00*\n",
    "\n",
    "**Inference:**\n",
    "\n",
    "*The linear SVM achieved near-perfect performance.*\n",
    "\n",
    "*The model performed best with a higher C (100), suggesting it benefited from stricter classification with fewer margin violations.*\n",
    "\n",
    "*Likely, the data is linearly separable or close to it.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b781da3f-9059-4157-977d-6ed826613e1a",
   "metadata": {},
   "source": [
    "### RBF Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "20b79f62-cabe-402a-8361-d8dda553dc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C (RBF): {'C': 1}\n",
      "Accuracy (RBF): 0.9815\n",
      "Classification Report (RBF):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       693\n",
      "           1       0.99      0.98      0.99      1307\n",
      "\n",
      "    accuracy                           0.98      2000\n",
      "   macro avg       0.98      0.98      0.98      2000\n",
      "weighted avg       0.98      0.98      0.98      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RBF Kernel\n",
    "grid_rbf = GridSearchCV(SVC(kernel='rbf', random_state=42), param_grid, scoring='accuracy')\n",
    "grid_rbf.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_rbf = grid_rbf.best_estimator_\n",
    "y_pred_rbf = best_rbf.predict(X_test_scaled)\n",
    "\n",
    "print(\"Best C (RBF):\", grid_rbf.best_params_)\n",
    "print(\"Accuracy (RBF):\", accuracy_score(y_test, y_pred_rbf))\n",
    "print(\"Classification Report (RBF):\\n\", classification_report(y_test, y_pred_rbf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15e68fd-f54d-4ce8-afb6-3909d41c0246",
   "metadata": {},
   "source": [
    "**Report:**\n",
    "\n",
    "*High performance with slightly lower accuracy than the linear model.*\n",
    "\n",
    "*C = 1 provided the best generalization, balancing margin width and training accuracy.*\n",
    "\n",
    "**Inference:**\n",
    "\n",
    "*RBF captured some nonlinear structure but was slightly less effective than linear for this dataset.*\n",
    "\n",
    "*Still robust, showing excellent precision and recall.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac39f7a-7e0f-4a7f-8168-305378dbc0ab",
   "metadata": {},
   "source": [
    "### Polynomial Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bc40e7f8-dca4-4bc3-80df-7235d03c2140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C (Polynomial): {'C': 10}\n",
      "Accuracy (Polynomial): 0.969\n",
      "Classification Report (Polynomial):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96       693\n",
      "           1       0.98      0.98      0.98      1307\n",
      "\n",
      "    accuracy                           0.97      2000\n",
      "   macro avg       0.97      0.97      0.97      2000\n",
      "weighted avg       0.97      0.97      0.97      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Polynomial Kernel\n",
    "grid_poly = GridSearchCV(SVC(kernel='poly', degree=3, random_state=42), param_grid, scoring='accuracy')\n",
    "grid_poly.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_poly = grid_poly.best_estimator_\n",
    "y_pred_poly = best_poly.predict(X_test_scaled)\n",
    "\n",
    "print(\"Best C (Polynomial):\", grid_poly.best_params_)\n",
    "print(\"Accuracy (Polynomial):\", accuracy_score(y_test, y_pred_poly))\n",
    "print(\"Classification Report (Polynomial):\\n\", classification_report(y_test, y_pred_poly))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b33980-fbdc-4968-80fb-f852ec8d7cc0",
   "metadata": {},
   "source": [
    "**Report:**\n",
    "\n",
    "*Strong performance, though slightly behind RBF and Linear.*\n",
    "\n",
    "*Best performance at C = 10 indicates moderate regularization worked well.*\n",
    "\n",
    "**Inference:**\n",
    "\n",
    "*Polynomial kernel adds complexity (nonlinear decision boundaries).*\n",
    "\n",
    "*Possibly overfits more than necessary on this dataset compared to linear/RBF.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81499eaf-95ba-4863-8875-5c2d15983119",
   "metadata": {},
   "source": [
    "## 8. Comparison and Discussion of SVM Kernel Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f878ba-b125-4533-bf79-086942a88e2e",
   "metadata": {},
   "source": [
    "#### Key Observations:\n",
    "\n",
    "**1. Linear Kernel**\n",
    "\n",
    "*Top performer with ~99.8% accuracy.*\n",
    "\n",
    "*Extremely high precision and recall for both classes.*\n",
    "\n",
    "*Indicates the dataset is likely linearly separable or very close to it.*\n",
    "\n",
    "*Model is simpler and more efficient compared to nonlinear kernels.*\n",
    "\n",
    "\n",
    "**2. RBF Kernel**\n",
    "\n",
    "*Performs nearly as well as the linear kernel.*\n",
    "\n",
    "*Good generalization ability, capturing nonlinear relationships.*\n",
    "\n",
    "*Best performance at C = 1, suggesting a good trade-off between margin and misclassification.*\n",
    "\n",
    "*Useful if data is not linearly separable, but adds computation cost.*\n",
    "\n",
    "**3. Polynomial Kernel**\n",
    "\n",
    "*Slightly lower accuracy (96.9%) than linear and RBF.*\n",
    "\n",
    "*May have overfit slightly due to increased model complexity (degree-3 polynomial).*\n",
    "\n",
    "*Still performs well but may not justify added complexity on this dataset.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84c2461-4889-4691-8807-7ed4d10af937",
   "metadata": {},
   "source": [
    "**Linear SVM is the best choice for this dataset due to its simplicity and top accuracy.**\n",
    "\n",
    "**RBF is a strong fallback for handling nonlinear patterns, with competitive results.**\n",
    "\n",
    "**Polynomial kernel is more complex and does not outperform simpler alternatives here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a98dc5d-e9a1-4bbb-87c9-d3575515064c",
   "metadata": {},
   "source": [
    "## END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
